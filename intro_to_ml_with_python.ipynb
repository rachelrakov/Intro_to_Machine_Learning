{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning with scikit-learn\n",
    "### Rachel Rakov\n",
    "Welcome!  In this workshop, we are going to learn how to go through the process of doing *machine learning* on a set of data.   To do so, we will download a *corpus* of text data to work with, extract *features* from this data, and do *supervised* machine learning to our data, using a mathmatical algorithm to train a*classifier* which will then classify previously unseen data into a set of predefined categories.\n",
    "\n",
    "\n",
    "\"Machine learning is a research field that sits at the intersections of statistics, artificial intelligence, and computer science.  It is also known as *predictive analystics* or *statistical learning*.\"\n",
    "\n",
    "-- Andreas Mueller, \"Introduction to Machine Learning with Python\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key terms\n",
    "- *machine learning*: An application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed\n",
    "\n",
    "\n",
    "- *corpus*: A large collection of data.  In our case, this will be text data (although a corpus can contain any type of data)\n",
    "\n",
    "\n",
    "- *features*: Properties that describe data entities for machine learning\n",
    "\n",
    "\n",
    "- *feature representation, feature vector*: A set of features\n",
    "\n",
    "\n",
    "- *supervised machine learning*:  A machine learning task of learning a function that maps an input to an output based on example input-output pairs\n",
    "\n",
    "\n",
    "- *unsupervised machine learning*: A machine learning task used to draw inferences from datasets consisting of input data without labeled responses (lacks input-output pairs; only has input data)\n",
    "\n",
    "\n",
    "- *algorithm*: A process or set of rules to be followed in calculations (or other problem-solving operations), particularly by a computer\n",
    "\n",
    "\n",
    "- *classification*: An machine learning task used to predict a class label, which is a choice from a predefined list of possibilities\n",
    "\n",
    "Sources: Wikipedia, Andreas Mueller's \"Introduction to Machine Learning with Python\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals of this workshop\n",
    "In this workshop, you will learn the following skills:\n",
    "- How to use skills from the NLTK workshop to build features for a classification task\n",
    "- How to build a text classification system that can predict whether sentences belong to one category (\"news\") or another (\"romance\")\n",
    "- How to prepare data for machine learning using *pandas*, a package for Python that helps to organize your data\n",
    "    - Looks similar to an Excel spreadsheet\n",
    "- How to use the scikit-learn package for Python to perform machine learning on the data\n",
    "- How to evaluate the results of the classifier, helping to decide whether the classifier is effective\n",
    "- How to adjust paramaters of a classifier to improve accuracy\n",
    "\n",
    "### What do you need for this workshop?\n",
    "- Python 3\n",
    "    - You can also download the Jupyter Notebook for this lesson to follow along\n",
    "- The Natural Lanugage Toolkit\n",
    "    - We will be using both corpora and tools from this package\n",
    "- pandas \n",
    "    - We will use this for data processing\n",
    "    - Comes with Anaconda\n",
    "- matplotlib\n",
    "    - We will use this for visualizing our data\n",
    "    - Comes with Anaconda\n",
    "- sckiit-learn\n",
    "    - We will use this for machine learning\n",
    "    - Comes with Anaconda \n",
    "\n",
    "### Let's get started by importing some packages we will need for this workshop!\n",
    "- The Brown Corpus: A text corpus of American English, split into fifteen different categories\n",
    "- Part of speech taggers (POS): prebuilt functions that are designed to determine the part of speech of every word in the sentence you give them\n",
    "- Pandas as pd: importing the Pandas toolkit and renaming it pd, so we don't have to type too much\n",
    "- matplotlib.pyplot as plt: importing plotting tools from matplotlib and renaming them plt\n",
    "    - ~~~\n",
    "    %matplotlib inline\n",
    "    ~~~\n",
    "    We use the above code to ensure our images display clearly in the Jupyter notebook.\n",
    "\n",
    "- sklearn: the scikit-learn machine learning toolkit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk import pos_tag_sents\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is classification?  Let's show an example using fruit!\n",
    "\n",
    "### How would you describe apples to a computer?  How would they differ from oranges?\n",
    "Remember, computers can only really understand numbers, true false values, and strings within a predefined set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fruit3](images/fruit3.png)\n",
    "Source: Andrew Rosenberg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our fruit test shows us everything we need to do a classification machine learning test. For each item with a *label* (apple, orange, lemon), we use a series of values to try to capture machine-understandable information about the item.  These values are a *feature representation* of the item in question.  The features themselves, as we can see above, can be numeric, true/false values, or a string in a set of predefined strings.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we had a new, unknown fruit?\n",
    "![fruit2](images/fruit2.png)\n",
    "Source: Andrew Rosenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our fruit test is an example of a *classification* task.  Classification allows you to predict a *categorical* value.  This is a type of *supervised* machine learning, meaning we know the labels ahead of time and can give them to the machine learning algorithm so that it can be trained to knows what the categories of our data are.  This way, when it comes time to give the previously algorithm previously unseen data, it knows which categories it's looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a thing about people who do work like this (Hannah?)\n",
    "- Viral Text\n",
    "- Rob Richmond (not sure what his work is, too common a name to goodgle without more info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get to coding!\n",
    "In this workshop we are going to *classify* two different sets of sentences from very different source material in the Brown corpus; one set of sentences from a corpus of news text, and the other set of sentences from a corpus of romance novel text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a list of catorigies in the Brown corpus, use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure\n",
      "belles_lettres\n",
      "editorial\n",
      "fiction\n",
      "government\n",
      "hobbies\n",
      "humor\n",
      "learned\n",
      "lore\n",
      "mystery\n",
      "news\n",
      "religion\n",
      "reviews\n",
      "romance\n",
      "science_fiction\n"
     ]
    }
   ],
   "source": [
    "for cat in brown.categories():\n",
    "    print (cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the sentences from each corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sent = brown.sents(categories=[\"news\"])\n",
    "romance_sent = brown.sents(categories=[\"romance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look at the first 5 sentences in each corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ['The', 'September-October', 'term', 'jury', 'had', 'been', 'charged', 'by', 'Fulton', 'Superior', 'Court', 'Judge', 'Durwood', 'Pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'Mayor-nominate', 'Ivan', 'Allen', 'Jr.', '.'], ['``', 'Only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.'], ['The', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', \"Georgia's\", 'registration', 'and', 'election', 'laws', '``', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', \"''\", '.']]\n",
      "\n",
      "[['They', 'neither', 'liked', 'nor', 'disliked', 'the', 'Old', 'Man', '.'], ['To', 'them', 'he', 'could', 'have', 'been', 'the', 'broken', 'bell', 'in', 'the', 'church', 'tower', 'which', 'rang', 'before', 'and', 'after', 'Mass', ',', 'and', 'at', 'noon', ',', 'and', 'at', 'six', 'each', 'evening', '--', 'its', 'tone', ',', 'repetitive', ',', 'monotonous', ',', 'never', 'breaking', 'the', 'boredom', 'of', 'the', 'streets', '.'], ['The', 'Old', 'Man', 'was', 'unimportant', '.'], ['Yet', 'if', 'he', 'were', 'not', 'there', ',', 'they', 'would', 'have', 'missed', 'him', ',', 'as', 'they', 'would', 'have', 'missed', 'the', 'sounds', 'of', 'bees', 'buzzing', 'against', 'the', 'screen', 'door', 'in', 'early', 'June', ';', ';'], ['or', 'the', 'smell', 'of', 'thick', 'tomato', 'paste', '--', 'the', 'ripe', 'smell', 'that', 'was', 'both', 'sweet', 'and', 'sour', '--', 'rising', 'up', 'from', 'aluminum', 'trays', 'wrapped', 'in', 'fly-dotted', 'cheesecloth', '.']]\n"
     ]
    }
   ],
   "source": [
    "print (news_sent[:5])\n",
    "print ()\n",
    "print (romance_sent[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you notice about the format of the data above?\n",
    "Each sentence is already *tokenized* - split into a series of word and punctuation stringes, with whitespace removed. This saves us the time of having to do all of this work ourselves!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start to organize our data, let's put these sentences into a pandas *DataFrame*, an object which has a format very similar to an Excel spreadsheet.  We will first make two spread sheets (one for news, and one for romance), and then combine them into one.  We will also add the category each sentences came from, which will be our *labels* for each sentence and its associated feature representation (which we will build ourselves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = pd.DataFrame({'sentence': news_sent,\n",
    "                    'label':'news'})\n",
    "rdf = pd.DataFrame({'sentence':romance_sent, \n",
    "                    'label':'romance'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining two spreadsheets into 1\n",
    "df = pd.concat([ndf, rdf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what this DataFrame looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, Fulton, County, Grand, Jury, said, Frida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, further, said, in, term-end, prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, September-October, term, jury, had, been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>[``, Only, a, relative, handful, of, such, rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, said, it, did, find, that, many, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>news</td>\n",
       "      <td>[It, recommended, that, Fulton, legislators, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, grand, jury, commented, on, a, number, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>news</td>\n",
       "      <td>[Merger, proposed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>news</td>\n",
       "      <td>[However, ,, the, jury, said, it, believes, ``...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, City, Purchasing, Department, ,, the, ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>news</td>\n",
       "      <td>[It, urged, that, the, city, ``, take, steps, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>news</td>\n",
       "      <td>[Implementation, of, Georgia's, automobile, ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>news</td>\n",
       "      <td>[It, urged, that, the, next, Legislature, ``, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, grand, jury, took, a, swipe, at, the, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>news</td>\n",
       "      <td>[``, This, is, one, of, the, major, items, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jurors, said, they, realize, ``, a, prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>news</td>\n",
       "      <td>[Nevertheless, ,, ``, we, feel, that, in, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>news</td>\n",
       "      <td>[``, Failure, to, do, this, will, continue, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, also, commented, on, the, Fulton, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>news</td>\n",
       "      <td>[Wards, protected]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, said, it, found, the, court, ``, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>news</td>\n",
       "      <td>[``, These, actions, should, serve, to, protec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>news</td>\n",
       "      <td>[Regarding, Atlanta's, new, multi-million-doll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, did, not, elaborate, ,, but, it, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>news</td>\n",
       "      <td>[Ask, jail, deputies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>news</td>\n",
       "      <td>[On, other, matters, ,, the, jury, recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>news</td>\n",
       "      <td>[Four, additional, deputies, be, employed, at,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>news</td>\n",
       "      <td>[(, 2, )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>news</td>\n",
       "      <td>[Fulton, legislators, ``, work, with, city, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, praised, the, administration, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Let's, make, it, moonlight, and, the, call, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Ticonderoga, folded, a, few, minutes, too, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>romance</td>\n",
       "      <td>[We've, got, rid, of, the, steam, yachts, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Why, not, come, down, smartly, in, the, world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>romance</td>\n",
       "      <td>[He, swayed, them, somewhat, ,, but, the, deba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Financing, emerged, as, the, main, obstacle, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Mr., Willis, made, it, evident, that, he, had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, Nobody, will, underwrite, it, ,, I'm, tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, I, know, what, I'm, talking, about, in, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, There's, plenty, of, risk, money, '', ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, All, right, '', ,, William, said, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, We'll, try, to, swing, the, deal, on, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>romance</td>\n",
       "      <td>[If, we, can't, raise, the, capital, ,, we're,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Nothing, has, been, lost, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>romance</td>\n",
       "      <td>[You're, up, against, it, anyhow, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Why, won't, you, give, me, a, chance, '', ?, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417</th>\n",
       "      <td>romance</td>\n",
       "      <td>[A, silence, fell, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4418</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Heads, instinctively, turned, in, Willis', di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>romance</td>\n",
       "      <td>[He, smiled, at, William, and, slowly, rubbed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, I, feel, I, must, answer, the, question, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>romance</td>\n",
       "      <td>[I'm, not, giving, you, a, chance, ,, Bill, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Good, luck, to, you, '', .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, All, the, in-laws, have, got, to, have, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Sweat, started, out, on, William's, forehead,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Across, the, table, ,, Hamrick, saluted, him,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Nobody, else, showed, pleasure, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Spike-haired, ,, burly, ,, red-faced, ,, deck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, Hello, ,, boss, '', ,, he, said, ,, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, I, suppose, I, can, never, expect, to, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, I'm, afraid, not, '', .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9054 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                           sentence\n",
       "0        news  [The, Fulton, County, Grand, Jury, said, Frida...\n",
       "1        news  [The, jury, further, said, in, term-end, prese...\n",
       "2        news  [The, September-October, term, jury, had, been...\n",
       "3        news  [``, Only, a, relative, handful, of, such, rep...\n",
       "4        news  [The, jury, said, it, did, find, that, many, o...\n",
       "5        news  [It, recommended, that, Fulton, legislators, a...\n",
       "6        news  [The, grand, jury, commented, on, a, number, o...\n",
       "7        news                                 [Merger, proposed]\n",
       "8        news  [However, ,, the, jury, said, it, believes, ``...\n",
       "9        news  [The, City, Purchasing, Department, ,, the, ju...\n",
       "10       news  [It, urged, that, the, city, ``, take, steps, ...\n",
       "11       news  [Implementation, of, Georgia's, automobile, ti...\n",
       "12       news  [It, urged, that, the, next, Legislature, ``, ...\n",
       "13       news  [The, grand, jury, took, a, swipe, at, the, St...\n",
       "14       news  [``, This, is, one, of, the, major, items, in,...\n",
       "15       news  [The, jurors, said, they, realize, ``, a, prop...\n",
       "16       news  [Nevertheless, ,, ``, we, feel, that, in, the,...\n",
       "17       news  [``, Failure, to, do, this, will, continue, to...\n",
       "18       news  [The, jury, also, commented, on, the, Fulton, ...\n",
       "19       news                                 [Wards, protected]\n",
       "20       news  [The, jury, said, it, found, the, court, ``, h...\n",
       "21       news  [``, These, actions, should, serve, to, protec...\n",
       "22       news  [Regarding, Atlanta's, new, multi-million-doll...\n",
       "23       news  [The, jury, did, not, elaborate, ,, but, it, a...\n",
       "24       news                              [Ask, jail, deputies]\n",
       "25       news  [On, other, matters, ,, the, jury, recommended...\n",
       "26       news  [Four, additional, deputies, be, employed, at,...\n",
       "27       news                                          [(, 2, )]\n",
       "28       news  [Fulton, legislators, ``, work, with, city, of...\n",
       "29       news  [The, jury, praised, the, administration, and,...\n",
       "...       ...                                                ...\n",
       "4401  romance  [Let's, make, it, moonlight, and, the, call, o...\n",
       "4402  romance  [Ticonderoga, folded, a, few, minutes, too, so...\n",
       "4403  romance  [We've, got, rid, of, the, steam, yachts, and,...\n",
       "4404  romance  [Why, not, come, down, smartly, in, the, world...\n",
       "4405  romance  [He, swayed, them, somewhat, ,, but, the, deba...\n",
       "4406  romance   [Financing, emerged, as, the, main, obstacle, .]\n",
       "4407  romance  [Mr., Willis, made, it, evident, that, he, had...\n",
       "4408  romance  [``, Nobody, will, underwrite, it, ,, I'm, tel...\n",
       "4409  romance  [``, I, know, what, I'm, talking, about, in, t...\n",
       "4410  romance  [``, There's, plenty, of, risk, money, '', ,, ...\n",
       "4411  romance          [``, All, right, '', ,, William, said, .]\n",
       "4412  romance  [``, We'll, try, to, swing, the, deal, on, tha...\n",
       "4413  romance  [If, we, can't, raise, the, capital, ,, we're,...\n",
       "4414  romance                      [Nothing, has, been, lost, .]\n",
       "4415  romance               [You're, up, against, it, anyhow, .]\n",
       "4416  romance   [Why, won't, you, give, me, a, chance, '', ?, ?]\n",
       "4417  romance                              [A, silence, fell, .]\n",
       "4418  romance  [Heads, instinctively, turned, in, Willis', di...\n",
       "4419  romance  [He, smiled, at, William, and, slowly, rubbed,...\n",
       "4420  romance  [``, I, feel, I, must, answer, the, question, ...\n",
       "4421  romance  [I'm, not, giving, you, a, chance, ,, Bill, ,,...\n",
       "4422  romance                       [Good, luck, to, you, '', .]\n",
       "4423  romance  [``, All, the, in-laws, have, got, to, have, t...\n",
       "4424  romance  [Sweat, started, out, on, William's, forehead,...\n",
       "4425  romance  [Across, the, table, ,, Hamrick, saluted, him,...\n",
       "4426  romance                [Nobody, else, showed, pleasure, .]\n",
       "4427  romance  [Spike-haired, ,, burly, ,, red-faced, ,, deck...\n",
       "4428  romance  [``, Hello, ,, boss, '', ,, he, said, ,, and, ...\n",
       "4429  romance  [``, I, suppose, I, can, never, expect, to, ca...\n",
       "4430  romance                      [``, I'm, afraid, not, '', .]\n",
       "\n",
       "[9054 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, Fulton, County, Grand, Jury, said, Frida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, further, said, in, term-end, prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, September-October, term, jury, had, been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>[``, Only, a, relative, handful, of, such, rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, said, it, did, find, that, many, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           sentence\n",
       "0  news  [The, Fulton, County, Grand, Jury, said, Frida...\n",
       "1  news  [The, jury, further, said, in, term-end, prese...\n",
       "2  news  [The, September-October, term, jury, had, been...\n",
       "3  news  [``, Only, a, relative, handful, of, such, rep...\n",
       "4  news  [The, jury, said, it, did, find, that, many, o..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how many labels do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news       4623\n",
       "romance    4431\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we want to visualize that information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEeCAYAAABsaamyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeae8753198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = df['label'].value_counts().plot.bar(ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have slightly more news data than romance data, which we should keep in mind as we go ahead with classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What should we use as features for our data set?  What did we use as features for our fruit example before?\n",
    "![fruit3](images/fruit3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we are using sentences, how can we best repersent each sentence as a series of values?\n",
    "\n",
    "One idea is to use how many particular *parts of speech* the sentence contains.\n",
    "\n",
    "- Nouns: Most basically described as a person, place, or thing.  Counting nouns can help determine how many topics are being discussed in a sentence.\n",
    "- Adjectives: Descriptors of nouns (eg. \"yellow\", \"angry\", \"charming\").  Counting adjectives can help determine how often descriptive words are being added to nouns, which can demonstrate writing style.\n",
    "- Adverbs: Descriptors of verbs (eg. \"quickly\", \"hungrily\", \"annoyingly\").  Counting adverbs can help determine how often the manner of the verb is modified, which can also demonstrate writing style.\n",
    "\n",
    "#### Why might we want to use these parts of speech to distinguish between news sentences and romance sentences?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute all of the parts of speech on each sentence (row) in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute parts of speech on each sentence (row)\n",
    "pos_all = pos_tag_sents(df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'DT'), ('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP'), ('said', 'VBD'), ('Friday', 'NNP'), ('an', 'DT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NNP'), ('recent', 'JJ'), ('primary', 'JJ'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'DT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'IN'), ('any', 'DT'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'DT'), ('jury', 'NN'), ('further', 'RB'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'JJ'), ('presentments', 'NNS'), ('that', 'IN'), ('the', 'DT'), ('City', 'NNP'), ('Executive', 'NNP'), ('Committee', 'NNP'), (',', ','), ('which', 'WDT'), ('had', 'VBD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'DT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'DT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('City', 'NNP'), ('of', 'IN'), ('Atlanta', 'NNP'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'DT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'DT'), ('election', 'NN'), ('was', 'VBD'), ('conducted', 'VBN'), ('.', '.')], [('The', 'DT'), ('September-October', 'NNP'), ('term', 'NN'), ('jury', 'NN'), ('had', 'VBD'), ('been', 'VBN'), ('charged', 'VBN'), ('by', 'IN'), ('Fulton', 'NNP'), ('Superior', 'NNP'), ('Court', 'NNP'), ('Judge', 'NNP'), ('Durwood', 'NNP'), ('Pye', 'NNP'), ('to', 'TO'), ('investigate', 'VB'), ('reports', 'NNS'), ('of', 'IN'), ('possible', 'JJ'), ('``', '``'), ('irregularities', 'NNS'), (\"''\", \"''\"), ('in', 'IN'), ('the', 'DT'), ('hard-fought', 'JJ'), ('primary', 'NN'), ('which', 'WDT'), ('was', 'VBD'), ('won', 'VBN'), ('by', 'IN'), ('Mayor-nominate', 'NNP'), ('Ivan', 'NNP'), ('Allen', 'NNP'), ('Jr.', 'NNP'), ('.', '.')], [('``', '``'), ('Only', 'RB'), ('a', 'DT'), ('relative', 'JJ'), ('handful', 'NN'), ('of', 'IN'), ('such', 'JJ'), ('reports', 'NNS'), ('was', 'VBD'), ('received', 'VBN'), (\"''\", \"''\"), (',', ','), ('the', 'DT'), ('jury', 'NN'), ('said', 'VBD'), (',', ','), ('``', '``'), ('considering', 'VBG'), ('the', 'DT'), ('widespread', 'JJ'), ('interest', 'NN'), ('in', 'IN'), ('the', 'DT'), ('election', 'NN'), (',', ','), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('voters', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('size', 'NN'), ('of', 'IN'), ('this', 'DT'), ('city', 'NN'), (\"''\", \"''\"), ('.', '.')], [('The', 'DT'), ('jury', 'NN'), ('said', 'VBD'), ('it', 'PRP'), ('did', 'VBD'), ('find', 'VB'), ('that', 'IN'), ('many', 'JJ'), ('of', 'IN'), (\"Georgia's\", 'NNP'), ('registration', 'NN'), ('and', 'CC'), ('election', 'NN'), ('laws', 'NNS'), ('``', '``'), ('are', 'VBP'), ('outmoded', 'VBN'), ('or', 'CC'), ('inadequate', 'JJ'), ('and', 'CC'), ('often', 'RB'), ('ambiguous', 'JJ'), (\"''\", \"''\"), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print (pos_all[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's with those part of speech labels?  They aren't helpful at all!\n",
    "The Penn Tagset, which NLTK uses for it's part of speech tagger, is not particularly intuitive.  Fortunately, they provide code that allows you to check what different tags stand for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset(\"NN\")\n",
    "nltk.help.upenn_tagset(\"JJ\")\n",
    "nltk.help.upenn_tagset(\"RB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function that calculates our features for us \n",
    "#### (In this case, numbers of nouns, adjectives, and adverbs that appear in the sentence)\n",
    "\n",
    "Now we know the tags for the different parts of speech we want to count in each sentence.  Let's now write a function that will count the parts of speech to us, when given a part of speech tagged sentence (such as we have already in our DataFrame) and the part of speech we want to count (for example, \"NN\" to count the number of nouns in the sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countPOS(pos_tag_sent, POS):\n",
    "    pos_count = 0\n",
    "    all_pos_counts = []\n",
    "    for sentence in pos_tag_sent:\n",
    "        for word in sentence:\n",
    "            tag = word[1]\n",
    "            if tag [:2] == POS:  \n",
    "                pos_count = pos_count+1\n",
    "        all_pos_counts.append(pos_count)\n",
    "        pos_count = 0\n",
    "    return all_pos_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now call this function three different times, one for each of the parts of speech we are counting.  As we finish counting them, we put the results into the DataFrame, saving us the trouble of having to do so later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NN'] = countPOS(pos_all, 'NN')\n",
    "df['JJ'] = countPOS(pos_all, \"JJ\")\n",
    "df['RB'] = countPOS(pos_all, \"RB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>NN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, Fulton, County, Grand, Jury, said, Frida...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, further, said, in, term-end, prese...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, September-October, term, jury, had, been...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>[``, Only, a, relative, handful, of, such, rep...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>[The, jury, said, it, did, find, that, many, o...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           sentence  NN  JJ  RB\n",
       "0  news  [The, Fulton, County, Grand, Jury, said, Frida...  11   2   0\n",
       "1  news  [The, jury, further, said, in, term-end, prese...  13   2   1\n",
       "2  news  [The, September-October, term, jury, had, been...  16   2   0\n",
       "3  news  [``, Only, a, relative, handful, of, such, rep...   9   3   1\n",
       "4  news  [The, jury, said, it, did, find, that, many, o...   5   3   1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>NN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Nobody, else, showed, pleasure, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>romance</td>\n",
       "      <td>[Spike-haired, ,, burly, ,, red-faced, ,, deck...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, Hello, ,, boss, '', ,, he, said, ,, and, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, I, suppose, I, can, never, expect, to, ca...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>romance</td>\n",
       "      <td>[``, I'm, afraid, not, '', .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                           sentence  NN  JJ  RB\n",
       "4426  romance                [Nobody, else, showed, pleasure, .]   2   0   1\n",
       "4427  romance  [Spike-haired, ,, burly, ,, red-faced, ,, deck...   9   3   1\n",
       "4428  romance  [``, Hello, ,, boss, '', ,, he, said, ,, and, ...   2   0   0\n",
       "4429  romance  [``, I, suppose, I, can, never, expect, to, ca...   3   0   1\n",
       "4430  romance                      [``, I'm, afraid, not, '', .]   1   0   1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how many features do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>RB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>31593</td>\n",
       "      <td>6678</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>13821</td>\n",
       "      <td>4022</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NN    JJ    RB\n",
       "label                     \n",
       "news     31593  6678  2935\n",
       "romance  13821  4022  3570"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize this data!\n",
    "What do you notice about the data when we look visualize it?  Do you think our features will be good at predicting news and romance sentences?  Which features do you think will be the most useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAFiCAYAAABcVRQBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeae8753358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(ncols=2,  figsize=(10,5))\n",
    "_ = df.groupby('label').sum().plot.bar(ax=ax1)\n",
    "_ = df.groupby('label').sum().T.plot.bar(ax=ax2, color=['gray','hotpink'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataframe to your computer as a csv file (comma separated value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Rachel/Documents/Grad_Stuff/DigitalFellows/NEHDRI_text_analysis/df_news_romance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin new notebook here?  On supervised and unsupervised machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does supervised machine learning work?\n",
    "Supervised machine learning takes places in two steps - the *training* phase, and the *testing* phase.  In the training phase, you use a portion of your data to *train* your algorithm (which, in our case, is a classification algorithm).  You provide both your feature vector and your labels to the algorithm, and the algorithm searches for patterns in your data that can help associate it with a particular label.\n",
    "\n",
    "In the testing phase, we use the classifier we trained in the previous step, and give it previously unseen feature vectors representing unseen data to the algorithm, and have the algorithm predict the label.  We can then compare the \"true\" label to the predicted label, and see if our classifier provides us with a good and generlizable way of accomplishing the task (in our case, the task of automatically distinguishing news sentences from romance sentences).\n",
    "\n",
    "![imagemlsteps](images/mlsteps.png)\n",
    "Source: Andrew Rosenberg\n",
    "\n",
    "\n",
    "It's important to remember that we cannot use the same data we used to build the classifier to test the data; if we did, our classifier would be 100% correct all of the time!  This will not tell us how our trained classifer will perform on new, unseen data.  We therefore need to split our data into a *train set* and a *test set*.\n",
    "- We will use the train set data to train our classifier\n",
    "- We will use the test set data to test our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for machine learning\n",
    "We're almost ready to do some machine learning!  First, we need to split our data into *feature vectors* and *labels*.  We need them separated to train the classifier.  Remember, the features we are using to train our classifier are numbers of nouns, adjectives, and adverbs are in each sentence.  (We are not using the sentences themselves as features!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NN  JJ  RB\n",
       "0  11   2   0\n",
       "1  13   2   1\n",
       "2  16   2   0\n",
       "3   9   3   1\n",
       "4   5   3   1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv = df[[\"NN\", \"JJ\", \"RB\"]]\n",
    "fv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news       4623\n",
       "romance    4431\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more news sentences than romance sentences; this is not a problem, but it's something to take note of during evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning data into train and test sets\n",
    "When you are partitioning your data into train and test sets, a good place to start is to use 75% of your data for training,and 25% of your data for testing.  We want as much training data as possible, while also having enough testing data to ensure that our trained classifier is generalizable across a number of examples.  This will also lead to more accurate evalutation of our trained classifier.\n",
    "\n",
    "Fortunately, sklearn has a function that will do exactly this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(fv, df['label'],\n",
    "                                                stratify=df['label'], \n",
    "                                                test_size=0.25,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use the \"stratify\" argument because we have an uneven amount of training data; we have more news sentances than romance sentences.  By using stratify, we ensure that our classifier will take this data imbalence into account.\n",
    "\n",
    "\n",
    "- In this example, we are using a fixed random state, to ensure we will always get exactly the same value when we classify.  Adding this argument is unnecessary for most types of classification; we do it here to ensure our results do not vary slightly across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6790, 3)\n",
      "(2264, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What classifier do I use?\n",
    "Chosing a classifier can be a challenging task.  However, this flowchart can give you an idea of where to start!\n",
    "\n",
    "![algorithms_cheatsheet](images/algorithms_cheatsheet.png)\n",
    "Source: Andreas Mueller\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this, we are going to use LinearSVC, which is a linear model for classification that separates classes using a line, a plane, or a hyperplane. SVC stands for \"Support Vector Classifier\", which is a type of support vector machine algorithm.\n",
    "\n",
    "![linearsvc](images/linearsvc.png)\n",
    "Source: Andreas Mueller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An animated example of classification \n",
    "The following animated GIF shows an example of linear classification.\n",
    "\n",
    "![croppedml](images/croppedml.gif)\n",
    "\n",
    "Source: Andrew Rosenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build a classification algorithm with sklearn!\n",
    "One of the best things about sklearn is the simplicity of its syntax.\n",
    "\n",
    "\n",
    "To do machine learning with sklearn, follow these three steps (the function names remain the same, regardless of the classifier you use!):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:  Import your desired classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create an instance of your machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:  Fit your data to your classifier (train), predict labels for unseen data (test), and score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70803886925795056"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, our classifier can predict previously unseen news and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predict)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|      |actual news | actual romance |\n",
    "|:--: | :--:| :--:|\n",
    "|predicted news | 759 | 397 |\n",
    "|predicted romance|282 | 826|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add visualization of the decision boundaries (Hannah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change paramaters example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every classification algorithm has paramaters, which we can see above where we created an instance of a classifier.\n",
    "\n",
    "~~~\n",
    "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "     verbose=0)\n",
    "~~~\n",
    "\n",
    "In our linear SVC example, the paramater is C, with a default of 1.0.  It is important to know that the default paramater is not always the best paramater for the data, and that it is common to try several different values of C in order to optimize the algorithm for your data.  In the code below, we show an example of searching through several different values of C to find the best value for paramater C for our particular data.  We search across our training data only, to ensure that we are not generalizing too closely to our testing data (which would be an example of *overfitting* our data to the classification algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.7082474226804124\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "grid_search = GridSearchCV(LinearSVC(), param_grid, cv=10)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our new optimal C paramater (which in our case happens to be the default paramater, though that is not always the case), we can reclassify, setting C manually with the result of C that we get from grid searching through different paramaters of C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearSVC(C=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70892226148409898"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add visualization or animation of the paramater searching (Hannah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the end, add some questions about ethics of machine learning (Hannah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
